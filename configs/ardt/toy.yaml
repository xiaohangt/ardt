method: ardt
normalize: false
train_args:
  gamma: 1.0
  scale: 5.0
  model_lr: 0.001
  model_wd: 0.0001
  batch_size: 128
  mse_epochs: 6
  maxmin_epochs: 12
  alpha: 0.01
  leaf_weight: 0.9
  ret_obs_act_model_args:
    hidden_size: 512
    num_layers: 2
    activation: "relu"
    batchnorm: False
    layernorm: False
    dropout: 0.0
  ret_model_args:
    hidden_size: 512
    num_layers: 2
    activation: "relu"
    batchnorm: False
    layernorm: False
    dropout: 0.0